# Projeto PS_IA: API de Triagem de Candidatos e Gera√ß√£o de Perguntas com Machine Learning

## üöÄ Vis√£o Geral do Projeto

O projeto **PS_IA** √© uma solu√ß√£o abrangente que integra Machine Learning e Intelig√™ncia Artificial Generativa para otimizar o processo de recrutamento e sele√ß√£o. Ele consiste em uma API robusta, desenvolvida com FastAPI, capaz de realizar a triagem autom√°tica de candidatos para vagas e, opcionalmente, gerar perguntas personalizadas para entrevistas utilizando um Large Language Model (LLM). Al√©m da API, o projeto inclui um pipeline completo para treinamento e monitoramento do modelo de Machine Learning, garantindo sua performance e adaptabilidade ao longo do tempo.

## üéØ Objetivos do Projeto

Os principais objetivos deste projeto s√£o:

1.  **Automatizar a Triagem de Candidatos**: Desenvolver um modelo de Machine Learning capaz de classificar candidatos com base em sua adequa√ß√£o a uma vaga, agilizando o processo de sele√ß√£o.
2.  **Otimizar o Processo de Entrevista**: Integrar um LLM para gerar perguntas de entrevista relevantes e personalizadas, tanto comuns quanto espec√≠ficas para cada candidato, a partir de descri√ß√µes de vagas e curr√≠culos.
3.  **Garantir a Qualidade do Modelo em Produ√ß√£o**: Implementar mecanismos de monitoramento de drift para detectar desvios nos dados ou no desempenho do modelo, assegurando sua efic√°cia cont√≠nua.
4.  **Fornecer uma API Escal√°vel e Robusta**: Construir uma API com FastAPI que seja f√°cil de integrar, perform√°tica e que ofere√ßa endpoints claros para predi√ß√£o e ranking de candidatos.

## üèóÔ∏è Arquitetura e Estrutura

O projeto segue uma arquitetura modular, dividida em componentes principais:

*   **API (FastAPI)**: Serve como interface para interagir com o modelo de ML e o LLM.
*   **M√≥dulo de Machine Learning**: Cont√©m o pipeline de treinamento, avalia√ß√£o e persist√™ncia do modelo.
*   **M√≥dulo de Pr√©-processamento**: Respons√°vel pela prepara√ß√£o dos dados para o treinamento e infer√™ncia.
*   **M√≥dulo de Gera√ß√£o de Perguntas (LLM)**: Integra√ß√£o com OpenAI para IA Generativa.
*   **M√≥dulo de Monitoramento**: Ferramentas para verificar a sa√∫de e performance do modelo em produ√ß√£o.

### Estrutura de Diret√≥rios Simplificada

```
PS_IA-main/
‚îú‚îÄ‚îÄ app/                         # Aplica√ß√£o FastAPI (endpoints, l√≥gica de neg√≥cio, LLM)
‚îú‚îÄ‚îÄ artifacts/                   # Artefatos gerados (relat√≥rios de drift)
‚îú‚îÄ‚îÄ configs/                     # Arquivos de configura√ß√£o
‚îú‚îÄ‚îÄ data/                        # Dados brutos e processados
‚îú‚îÄ‚îÄ models/prod/                 # Modelos treinados e metadados para a API
‚îú‚îÄ‚îÄ src/                         # C√≥digo fonte principal (ML, pr√©-processamento, monitoramento)
‚îÇ   ‚îú‚îÄ‚îÄ ml/                      # Pipeline de ML, treinamento, transformadores
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/              # L√≥gica de detec√ß√£o de drift
‚îÇ   ‚îî‚îÄ‚îÄ preprocess/              # Scripts de pr√©-processamento de dados
‚îú‚îÄ‚îÄ scripts/                     # Scripts utilit√°rios (check_drift, testadores)
‚îú‚îÄ‚îÄ tests/                       # Testes unit√°rios e de integra√ß√£o
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README_FINAL_GITHUB.md       # Este arquivo
```

## üõ†Ô∏è Tecnologias Utilizadas

*   **Python 3.8+**: Linguagem de programa√ß√£o principal.
*   **FastAPI**: Framework web para constru√ß√£o da API.
*   **Scikit-learn**: Biblioteca para Machine Learning (pipelines, transformadores).
*   **XGBoost**: Algoritmo de Machine Learning para classifica√ß√£o.
*   **Pandas**: Manipula√ß√£o e an√°lise de dados.
*   **Joblib**: Serializa√ß√£o de modelos Python.
*   **MLflow**: Plataforma para gerenciar o ciclo de vida de Machine Learning (rastreamento de experimentos, registro de modelos).
*   **OpenAI SDK**: Integra√ß√£o com modelos de linguagem (LLMs) para gera√ß√£o de texto.
*   **Pytest**: Framework para testes.
*   **uv / pip**: Gerenciadores de pacotes Python.

## ‚öôÔ∏è Como Rodar o Projeto


### Pr√©-requisitos

*   Python 3.8+
*   `uv` (recomendado) ou `pip`
*   Chave de API do OpenAI (se for testar a funcionalidade de gera√ß√£o de perguntas).

### 1. Configura√ß√£o do Ambiente

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone <URL_DO_REPOSITORIO>
    cd PS_IA-main
    ```

2.  **Instale `uv` (se n√£o tiver):**
    ```bash
    curl -LsSf https://astral.sh/uv/install.sh | sh
    ```

3.  **Crie e ative o ambiente virtual e instale as depend√™ncias:**
    ```bash
    uv sync
    source .venv/bin/activate
    ```
    *(Alternativamente, use `python -m venv .venv` e `pip install -r requirements.txt`)*

### 2. Sequ√™ncia de Execu√ß√£o

Para rodar o projeto do zero, siga a sequ√™ncia de passos abaixo:

#### 2.1. Download dos Dados Brutos (se necess√°rio)

Caso os dados brutos n√£o estejam dispon√≠veis, voc√™ pode baix√°-los:

```bash
# Exemplo de download 
curl -L "https://drive.google.com/uc?export=download&id=1h8Lk5LM8VE5TF80mngCcbsQ14qA2rbw_" -o data/raw/vagas.zip
unzip data/raw/vagas.zip -d data/raw/
curl -L "https://drive.google.com/uc?export=download&id=1Z0dOk8FMjazQo03PuUeNGZOW-rxtpzmO" -o data/raw/applicants.zip
unzip data/raw/applicants.zip -d data/raw/
curl -L "https://drive.google.com/uc?export=download&id=1-hNfS7Z01fMM_JnT2K-zQrOoGm_C-jUT" -o data/raw/prospects.zip
unzip data/raw/prospects.zip -d data/raw/
```

Os arquivos est√£o disponiveis no Google Drive, o link est√° em data/raw/links.txt.

Ap√≥s o download, descompacte os arquivos zip para o diret√≥rio `data/raw/`.

#### 2.2. Pr√©-processamento dos Dados

Esta etapa √© crucial para transformar os dados brutos em um formato utiliz√°vel pelo modelo. O script `src/ml/train_pipeline.py` espera o dataset consolidado `dataset_triagem_clean.csv` no diret√≥rio `data/processed/`.

Para gerar este arquivo, execute os scripts de pr√©-processamento na ordem correta. Por exemplo:

```bash
python src/preprocess/01_json_to_df.py
python src/preprocess/02_prepare_triagem.py
# Certifique-se de que o arquivo dataset_triagem_clean.csv seja gerado em data/processed/
```

**Observa√ß√£o:** Para fins de teste e avalia√ß√£o, se o arquivo `data/processed/dataset_triagem_clean.csv` j√° estiver dispon√≠vel (por exemplo, como `df_total` ou similar), esta etapa pode ser ignorada.

#### 2.3. Treinamento do Modelo

Com os dados processados dispon√≠veis, o modelo de Machine Learning pode ser treinado e salvo localmente para ser consumido pela API. Execute o script de treinamento:

```bash
python src/ml/train_pipeline.py
```

Este script ir√°:
*   Carregar o `dataset_triagem_clean.csv` de `data/processed/`.
*   Construir e treinar um pipeline de ML (XGBoost).
*   Avaliar o modelo e logar m√©tricas no MLflow (se configurado).
*   Salvar o modelo treinado (`model.joblib`) e seus metadados (`meta.json`) no diret√≥rio `models/prod/`.


### 3. Iniciar a API

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Ap√≥s iniciar, a API estar√° dispon√≠vel em `http://localhost:8000`. A documenta√ß√£o interativa (Swagger UI) pode ser acessada em `http://localhost:8000/docs`.

## üìä Principais Funcionalidades e Resultados

### API RESTful (FastAPI)

A API exp√µe os seguintes endpoints principais:

*   **`/health` (GET)**: Retorna o status da API e metadados do modelo carregado (vers√£o, m√©tricas, schema de entrada).
*   **`/schema` (GET)**: Apresenta o esquema de entrada esperado pelo modelo (colunas categ√≥ricas e de texto).
*   **`/predict` (POST)**: Realiza a predi√ß√£o para um √∫nico item (candidato/vaga), retornando a probabilidade de avan√ßo e a classifica√ß√£o.
*   **`/rank-and-suggest` (POST)**: Recebe uma vaga e uma lista de candidatos, retorna um ranking dos candidatos mais adequados e, opcionalmente, gera perguntas de entrevista via LLM.

#### Exemplo de Uso da API

**Endpoint: `/predict` (POST)**

**Entrada (JSON):**
```json
{
  "meta": {"external_id": "cand-11010"},
  "features": {
    "cv_pt": "Consultor SAP Basis com HANA e Fiori.",
    "informacoes_profissionais.conhecimentos_tecnicos": "SAP Basis, HANA, Fiori",
    "perfil_vaga.principais_atividades": "Gest√£o de incidentes e SLAs.",
    "perfil_vaga.competencia_tecnicas_e_comportamentais": "SAP Basis, lideran√ßa"
  }
}
```

**Sa√≠da (JSON):**
```json
{
  "meta": {"external_id": "cand-11010"},
  "prediction": {
    "prob_next_phase": 0.85,
    "label": 1,
    "threshold": 0.6
  },
  "model": {
    "name": "sklearn-pipeline-xgboost",
    "artifact": "model.joblib",
    "version": "2.0.0"
  }
}
```

**Endpoint: `/rank-and-suggest` (POST)**

**Entrada (JSON):**
```json
{
  "vaga": {
    "perfil_vaga.principais_atividades": "Opera√ß√µes e gest√£o de incidentes, SLAs.",
    "perfil_vaga.competencia_tecnicas_e_comportamentais": "SAP Basis, lideran√ßa"
  },
  "candidatos": [
    {
      "meta": {"external_id": "11010"},
      "candidato": {
        "cv_pt": "Experi√™ncia forte em SAP Basis e HANA.",
        "informacoes_profissionais.conhecimentos_tecnicos": "SAP Basis, HANA, Fiori"
      }
    },
    {
      "meta": {"external_id": "11011"},
      "candidato": {
        "cv_pt": "Gest√£o de opera√ß√µes e incidentes, ITIL.",
        "informacoes_profissionais.conhecimentos_tecnicos": "ITIL, SLAs, Linux"
      }
    }
  ]
}
```

**Sa√≠da (JSON - com `include_questions=True`):**
```json
{
  "job_meta": {
    "perfil_vaga.principais_atividades": "Opera√ß√µes e gest√£o de incidentes, SLAs.",
    "perfil_vaga.competencia_tecnicas_e_comportamentais": "SAP Basis, lideran√ßa"
  },
  "top_k": 5,
  "threshold_used": 0.6,
  "results": [
    {
      "external_id": "11010",
      "prob_next_phase": 0.92,
      "label": 1
    },
    {
      "external_id": "11011",
      "prob_next_phase": 0.78,
      "label": 1
    }
  ],
  "questions": {
    "common_questions": [
      "Quais s√£o suas principais experi√™ncias com gest√£o de incidentes e SLAs?",
      "Como voc√™ lida com a press√£o em ambientes de alta demanda?",
      "Descreva uma situa√ß√£o em que voc√™ demonstrou lideran√ßa t√©cnica.",
      "Quais s√£o seus conhecimentos em SAP Basis e como os aplicaria nesta fun√ß√£o?",
      "Como voc√™ se mant√©m atualizado sobre as novas tecnologias em sua √°rea?"
    ],
    "per_candidate": {
      "11010": [
        "Pode detalhar sua experi√™ncia com HANA e Fiori no contexto de SAP Basis?",
        "Como sua experi√™ncia em SAP Basis se alinha com a gest√£o de incidentes?",
        "Descreva um projeto desafiador em que voc√™ utilizou SAP Basis e HANA."
      ],
      "11011": [
        "Qual sua experi√™ncia com ITIL e como ela contribui para a gest√£o de opera√ß√µes?",
        "Como voc√™ aplicaria seus conhecimentos em Linux para otimizar SLAs?",
        "Pode descrever um cen√°rio onde sua experi√™ncia em gest√£o de incidentes foi crucial?"
      ]
    }
  }
}
```

### 4. Executar com Docker

Se preferir rodar a aplica√ß√£o via Docker, sem precisar configurar o ambiente Python localmente, siga os passos abaixo:

#### 4.1. Construir a imagem
No diret√≥rio raiz do projeto (onde est√° o `Dockerfile`), execute:

```bash
docker build -t ps_ia:with-model .
```
Isso criar√° uma imagem chamada ps_ia:with-model

#### 4.2. Rodar o container
Para iniciar a aplica√ß√£o, expondo a porta 8000
```bash
docker run -it --rm -p 8000:8000 \
  -e OPENAI_API_KEY="sua-chave-aqui" \
  ps_ia:with-model
```
OPENAI_API_KEY= necess√°ria se quiser utilizar a feature de gerar perguntas para os candidatos

#### 4.3. Usando .env
Para n√£o expor a chave diretamente na linha de comando, voc√™ pode criar um arquivo .env na raiz do projeto (n√£o commitado no Git) com o seguinte conte√∫do:
```
OPENAI_API_KEY=sua-chave-aqui
```
E rodar:
```bash
docker run -it --rm -p 8000:8000 --env-file .env ps_ia:with-model
```

Ap√≥s rodar o container, a API estar√° dispon√≠vel em:

Swagger UI: http://localhost:8000/docs

OpenAPI JSON: http://localhost:8000/openapi.json

## Modelo de Machine Learning

O modelo central para a triagem de candidatos √© um pipeline `scikit-learn` que incorpora um classificador **XGBoost**. A escolha do XGBoost se deu pela sua comprovada efic√°cia em problemas de classifica√ß√£o tabular, combinando alta performance, robustez a dados ruidosos e capacidade de lidar com desbalanceamento de classes (atrav√©s do par√¢metro `scale_pos_weight`). Ele √© treinado para identificar a probabilidade de um candidato avan√ßar para a pr√≥xima fase do processo seletivo.

#### Avalia√ß√£o e M√©tricas (Classification Report)

Durante o treinamento, o modelo √© avaliado em um conjunto de dados de *holdout* para garantir sua generaliza√ß√£o. As m√©tricas de avalia√ß√£o, incluindo ROC AUC, PR AUC e F1-Score, s√£o calculadas e logadas no MLflow. Al√©m disso, um `classification_report` detalhado √© gerado, fornecendo insights sobre o desempenho do modelo para cada classe (candidato avan√ßa vs. candidato n√£o avan√ßa).

**Exemplo de `classification_report` (valores ilustrativos):**

```
               precision    recall  f1-score   support

           0      0.417     0.696     0.521      1899
           1      0.802     0.558     0.659      4194

    accuracy                          0.601      6093
   macro avg      0.609     0.627     0.590      6093
weighted avg      0.682     0.601     0.616      6093

```

*   **Precision (Precis√£o)**: A propor√ß√£o de identifica√ß√µes positivas que estavam corretas. Para a classe `1` (candidato avan√ßa), uma precis√£o de 0.80 significa que 808% dos candidatos classificados como "avan√ßar" realmente avan√ßaram.
*   **Recall (Revoca√ß√£o/Sensibilidade)**: A propor√ß√£o de positivos reais que foram identificados corretamente. Para a classe `1`, um recall de 0.65 indica que o modelo identificou 65% de todos os candidatos que deveriam avan√ßar.
*   **F1-Score**: A m√©dia harm√¥nica da precis√£o e do recall. √â uma m√©trica √∫til quando h√° um desequil√≠brio de classes, fornecendo um equil√≠brio entre precis√£o e recall.
*   **Support**: O n√∫mero de ocorr√™ncias reais de cada classe no conjunto de teste.

Essas m√©tricas s√£o cruciais para entender o trade-off entre identificar corretamente os candidatos que avan√ßam (recall) e evitar falsos positivos (precision), sendo o F1-Score um bom indicador geral do desempenho do modelo para a classe minorit√°ria (candidatos que avan√ßam).

### Gera√ß√£o de Perguntas com LLM

A funcionalidade de `/rank-and-suggest` pode invocar um LLM (OpenAI) para gerar:

*   **Perguntas Comuns**: 5 perguntas gerais aplic√°veis a todos os candidatos para a vaga.
*   **Perguntas Personalizadas**: 3 perguntas espec√≠ficas para cada candidato, baseadas em seu curr√≠culo e na descri√ß√£o da vaga.

Esta funcionalidade visa enriquecer o processo de entrevista, fornecendo insights mais profundos sobre cada candidato.

### Monitoramento de Drift

O projeto inclui um script (`scripts/check_drift.py`) e um m√≥dulo (`src/monitoring/drift.py`) para monitorar o drift de dados e de modelo. Isso √© crucial para garantir que o modelo continue performando bem em produ√ß√£o, alertando sobre mudan√ßas nas caracter√≠sticas dos dados de entrada que possam impactar a qualidade das predi√ß√µes.

## ‚úÖ Testes

O projeto conta com uma su√≠te de testes abrangente (`tests/`) utilizando `pytest`, cobrindo:

*   **Testes de API**: Valida√ß√£o dos endpoints, respostas e tratamento de erros.
*   **Testes de L√≥gica de Neg√≥cio**: Verifica√ß√£o das fun√ß√µes auxiliares e do pr√©-processamento.
*   **Testes de Pipeline de ML**: Garantia da correta constru√ß√£o e funcionamento do pipeline de treinamento.
*   **Testes de LLM**: Valida√ß√£o da integra√ß√£o e sa√≠da da gera√ß√£o de perguntas.

- **Cobertura total:** 85%  

Comando utilizado:
```bash
  pytest --cov=app --cov=src
```

## Limita√ß√µes & Pr√≥ximos Passos 

    * Texto: TF-IDF √© bag-of-words; pr√≥ximo passo razo√°vel: embeddings (SBERT) e re-rankers.

    * Calibra√ß√£o: avaliar Brier e calibradores (Platt/Isotonic) para thresholds est√°veis.

    * Fairness/PII: auditoria sistem√°tica de vieses e refor√ßo de controles.

    * MLOps: model registry, shadow deploy, alertas autom√°ticos de drift.
