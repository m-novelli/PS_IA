# Projeto PS_IA: API de Triagem de Candidatos e Gera√ß√£o de Perguntas com Machine Learning e IA

## Vis√£o Geral do Projeto

O projeto **PS_IA** √© uma solu√ß√£o abrangente que integra Machine Learning e Intelig√™ncia Artificial Generativa para otimizar o processo de recrutamento e sele√ß√£o. Ele consiste em uma API, desenvolvida com FastAPI, capaz de realizar a triagem autom√°tica de candidatos para vagas e, opcionalmente, gerar perguntas personalizadas para entrevistas utilizando um Large Language Model (LLM). Al√©m da API, o projeto inclui um pipeline completo para treinamento e monitoramento do modelo de Machine Learning, garantindo sua performance e adaptabilidade ao longo do tempo.

## üéØ Objetivos do Projeto

Os principais objetivos deste projeto s√£o:

1.  **Automatizar a Triagem de Candidatos**: Desenvolver um modelo de Machine Learning capaz de classificar candidatos com base em sua adequa√ß√£o a uma vaga, agilizando o processo de sele√ß√£o.
2.  **Otimizar o Processo de Entrevista**: Integrar um LLM para gerar perguntas de entrevista relevantes e personalizadas, tanto comuns quanto espec√≠ficas para cada candidato, a partir de descri√ß√µes de vagas e curr√≠culos.
3.  **Garantir a Qualidade do Modelo em Produ√ß√£o**: Implementar mecanismos de monitoramento de drift para detectar desvios nos dados ou no desempenho do modelo, assegurando sua efic√°cia cont√≠nua.
4.  **Fornecer uma API Escal√°vel e Robusta**: Construir uma API com FastAPI que seja f√°cil de integrar, perform√°tica e que ofere√ßa endpoints claros para predi√ß√£o e ranking de candidatos.

##  Arquitetura e Estrutura

O projeto segue uma arquitetura modular, dividida em componentes principais:

*   **API (FastAPI)**: Serve como interface para interagir com o modelo de ML e o LLM.
*   **M√≥dulo de Machine Learning**: Cont√©m o pipeline de treinamento, avalia√ß√£o e persist√™ncia do modelo.
*   **M√≥dulo de Pr√©-processamento**: Respons√°vel pela prepara√ß√£o dos dados para o treinamento e infer√™ncia.
*   **M√≥dulo de Gera√ß√£o de Perguntas (LLM)**: Integra√ß√£o com OpenAI para IA Generativa.
*   **M√≥dulo de Monitoramento**: Ferramentas para verificar a sa√∫de e performance do modelo em produ√ß√£o.

### Estrutura de Diret√≥rios Simplificada

```
PS_IA-main/
‚îú‚îÄ‚îÄ app/                         # Aplica√ß√£o FastAPI (endpoints, l√≥gica de neg√≥cio, LLM)
‚îú‚îÄ‚îÄ artifacts/                   # Artefatos gerados (relat√≥rios de drift)
‚îú‚îÄ‚îÄ configs/                     # Arquivos de configura√ß√£o
‚îú‚îÄ‚îÄ data/                        # Dados brutos e processados
‚îú‚îÄ‚îÄ models/prod/                 # Modelos treinados e metadados para a API
‚îú‚îÄ‚îÄ src/                         # C√≥digo fonte principal (ML, pr√©-processamento, monitoramento)
‚îÇ   ‚îú‚îÄ‚îÄ ml/                      # Pipeline de ML, treinamento, transformadores
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/              # L√≥gica de detec√ß√£o de drift
‚îÇ   ‚îî‚îÄ‚îÄ preprocess/              # Scripts de pr√©-processamento de dados
‚îú‚îÄ‚îÄ scripts/                     # Scripts utilit√°rios (check_drift, testadores)
‚îú‚îÄ‚îÄ tests/                       # Testes unit√°rios e de integra√ß√£o
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README_FINAL_GITHUB.md       # Este arquivo
```

## üõ†Ô∏è Tecnologias Utilizadas

*   **Python 3.8+**: Linguagem de programa√ß√£o principal.
*   **FastAPI**: Framework web para constru√ß√£o da API.
*   **Scikit-learn**: Biblioteca para Machine Learning (pipelines, transformadores).
*   **XGBoost**: Algoritmo de Machine Learning para classifica√ß√£o.
*   **Pandas**: Manipula√ß√£o e an√°lise de dados.
*   **Joblib**: Serializa√ß√£o de modelos Python.
*   **MLflow**: Plataforma para gerenciar o ciclo de vida de Machine Learning (rastreamento de experimentos, registro de modelos).
*   **OpenAI SDK**: Integra√ß√£o com modelos de linguagem (LLMs) para gera√ß√£o de texto.
*   **Pytest**: Framework para testes.
*   **uv / pip**: Gerenciadores de pacotes Python.

## ‚öôÔ∏è Como Rodar o Projeto

Para que o professor possa analisar e executar o projeto, siga os passos abaixo:

### Pr√©-requisitos

*   Python 3.8+
*   `uv` (recomendado) ou `pip`
*   Chave de API do OpenAI (se for testar a funcionalidade de gera√ß√£o de perguntas).

### 1. Configura√ß√£o do Ambiente

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone <URL_DO_REPOSITORIO>
    cd PS_IA-main
    ```

2.  **Instale `uv` (se n√£o tiver):**
    ```bash
    curl -LsSf https://astral.sh/uv/install.sh | sh
    ```

3.  **Crie e ative o ambiente virtual e instale as depend√™ncias:**
    ```bash
uv sync
source .venv/bin/activate
    ```
    *(Alternativamente, use `python -m venv .venv` e `pip install -r requirements.txt`)*

### 2. Download dos Dados Brutos

Para replicar o ambiente de treinamento, voc√™ precisar√° dos dados. O projeto original usava `curl` para baixar arquivos zip do Google Drive. Adapte conforme a disponibilidade dos dados:

```bash

curl -L "https://drive.google.com/uc?export=download&id=1h8Lk5LM8VE5TF80mngCcbsQ14qA2rbw_" -o data/raw/vagas.zip
curl -L "https://drive.google.com/uc?export=download&id=1Z0dOk8FMjazQo03PuUeNGZOW-rxtpzmO" -o data/raw/applicants.zip
curl -L "https://drive.google.com/uc?export=download&id=1-hNfS7Z01fMM_JnT2K-zQrOoGm_C-jUT" -o data/raw/prospects.zip
# Descompacte os arquivos e execute os scripts de pr√©-processamento em src/preprocess/
```

### 3. Treinamento do Modelo

O modelo de Machine Learning √© treinado e salvo localmente para ser consumido pela API. Execute o script de treinamento:

```bash
python src/ml/train_pipeline.py
```

Este script ir√°:
*   Carregar os dados processados. O script `src/ml/train_pipeline.py` espera o dataset consolidado `dataset_triagem_clean.csv` no diret√≥rio `data/processed/`. Para fins de teste e avalia√ß√£o, se este arquivo j√° estiver dispon√≠vel (por exemplo, como `df_total` ou similar), a etapa de pr√©-processamento pode ser ignorada. Caso contr√°rio, ele deve ser gerado a partir dos dados brutos (`vagas.zip`, `applicants.zip`, `prospects.zip`) utilizando os scripts de pr√©-processamento em `src/preprocess/` (por exemplo, `01_json_to_df.py` e `02_prepare_triagem.py`).
*   Construir e treinar um pipeline de ML (XGBoost).
*   Avaliar o modelo e logar m√©tricas no MLflow (se configurado).
*   Salvar o modelo treinado (`model.joblib`) e seus metadados (`meta.json`) no diret√≥rio `models/prod/`.


### 4. Iniciar a API

Defina as vari√°veis de ambiente necess√°rias (especialmente `OPENAI_API_KEY` se for usar a funcionalidade de LLM) e inicie a aplica√ß√£o FastAPI:

```bash
export OPENAI_API_KEY="sua_chave_openai"


uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Ap√≥s iniciar, a API estar√° dispon√≠vel em `http://localhost:8000`. A documenta√ß√£o interativa (Swagger UI) pode ser acessada em `http://localhost:8000/docs`.

## üìä Principais Funcionalidades e Resultados

### API RESTful (FastAPI)

A API exp√µe os seguintes endpoints principais:

*   **`/health` (GET)**: Retorna o status da API e metadados do modelo carregado (vers√£o, m√©tricas, schema de entrada).
*   **`/schema` (GET)**: Apresenta o esquema de entrada esperado pelo modelo (colunas categ√≥ricas e de texto).
*   **`/predict` (POST)**: Realiza a predi√ß√£o para um √∫nico item (candidato/vaga), retornando a probabilidade de avan√ßo e a classifica√ß√£o.
*   **`/rank-and-suggest` (POST)**: Recebe uma vaga e uma lista de candidatos, retorna um ranking dos candidatos mais adequados e, opcionalmente, gera perguntas de entrevista via LLM.

### Modelo de Machine Learning

O modelo √© um pipeline `scikit-learn` com um classificador `XGBoost`, treinado para identificar a probabilidade de um candidato avan√ßar para a pr√≥xima fase do processo seletivo. As m√©tricas de avalia√ß√£o (ROC AUC, PR AUC, F1-Score) s√£o calculadas durante o treinamento e logadas no MLflow, demonstrando a performance do modelo em dados de holdout.

### Gera√ß√£o de Perguntas com LLM

A funcionalidade de `/rank-and-suggest` pode invocar um LLM (OpenAI) para gerar:

*   **Perguntas Comuns**: 5 perguntas gerais aplic√°veis a todos os candidatos para a vaga.
*   **Perguntas Personalizadas**: 3 perguntas espec√≠ficas para cada candidato, baseadas em seu curr√≠culo e na descri√ß√£o da vaga.

Esta funcionalidade visa enriquecer o processo de entrevista, fornecendo insights mais profundos sobre cada candidato.

### Monitoramento de Drift

O projeto inclui um script (`scripts/check_drift.py`) e um m√≥dulo (`src/monitoring/drift.py`) para monitorar o drift de dados e de modelo. Isso √© crucial para garantir que o modelo continue performando bem em produ√ß√£o, alertando sobre mudan√ßas nas caracter√≠sticas dos dados de entrada que possam impactar a qualidade das predi√ß√µes.

## ‚úÖ Testes

O projeto conta com uma su√≠te de testes abrangente (`tests/`) utilizando `pytest`, cobrindo:

*   **Testes de API**: Valida√ß√£o dos endpoints, respostas e tratamento de erros.
*   **Testes de L√≥gica de Neg√≥cio**: Verifica√ß√£o das fun√ß√µes auxiliares e do pr√©-processamento.
*   **Testes de Pipeline de ML**: Garantia da correta constru√ß√£o e funcionamento do pipeline de treinamento.
*   **Testes de LLM**: Valida√ß√£o da integra√ß√£o e sa√≠da da gera√ß√£o de perguntas.


